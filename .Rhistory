library(hexbin)
library(org.Hs.eg.db)
library(AnnotationDbi)
library(decoupleR)
library(dorothea)
library(reshape2)
library(tidyr)
library(GSEABase)
library(fgsea)
library(progeny)
library(limma)
library(factoextra)
library(NbClust)
source("scripts/support/support_functions.R")
## Raw counts table
load(file = 'data/RNA/counts_result.RData')
gene_counts <- as.data.frame(counts_result$counts)
count_df <- gene_counts
View(count_df)
names(count_df) <- gsub('.R1.fastq.gz.subread.BAM',"",names(count_df))
View(count_df)
write_csv(count_df, "../../data/RNA/counts_df.csv")
read_per_samples <- colSums(count_df)
names(read_per_samples) <- names(count_df)
plot(read_per_samples)
mean(read_per_samples)
median(read_per_samples)
#First we remove rows that contain only 0
count_df <- count_df[rowSums(count_df) > 0,]
#remaining 0 have to be made as NA so that log2 transformation is possible
count_df[count_df == 0] <- NA
#remove rows (genes) which aren't well-measured in enough samples
count_df <- count_df[rowSums(is.na(count_df)) < 40,]
#now we can normalise the cleaned dataframe using vsn
fit <- vsnMatrix(as.matrix(count_df)) #train vsn parameters
#make sure the mean/sd trend is not going crazy
meanSdPlot(fit)
#if good, normalise data with the trained parameters of vsn
count_df_vsn <- as.data.frame(vsn::predict(fit,as.matrix(count_df)))
write_csv(count_df_vsn, "../../data/RNA/counts_df_normalised.csv")
#now let's visualise the normalised data
targets <- as.data.frame(cbind(names(count_df_vsn),names(count_df_vsn)))
names(targets) <- c("sample","condition")
# plots <- magicPlotMakerLight(count_df_vsn, targets = targets)
# plot(plots[[1]])
# plot(plots[[2]])
map_table <- AnnotationDbi::mapIds(org.Hs.eg.db::org.Hs.eg.db, row.names(count_df_vsn),'SYMBOL','ENTREZID')
count_df_vsn$gene <- sapply(row.names(count_df_vsn), function(x, map_table){
return(map_table[x])
},map_table = map_table)
count_df_vsn <- count_df_vsn[!is.na(count_df_vsn$gene),]
row.names(count_df_vsn) <- count_df_vsn$gene
count_df_vsn <- count_df_vsn[,-dim(count_df_vsn)[2]]
count_df_vsn <- count_df_vsn[complete.cases(count_df_vsn),]
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '~/Dropbox/COSMOS_kidney_fibrosis_cohort_study/')
setwd('~/Dropbox/COSMOS_kidney_fibrosis_cohort_study/')
import_gmt <- function(gmtfile, fast = T)
{
if(fast)
{
genesets = GSEABase::getGmt(con = gmtfile)
genesets = unlist(genesets)
gene_to_term =plyr::ldply(genesets,function(geneset){
temp <- geneIds(geneset)
temp2 <- setName(geneset)
temp3 <- as.data.frame(cbind(temp,rep(temp2,length(temp))))
},.progress = plyr::progress_text())
names(gene_to_term) <- c("gene","term")
return(gene_to_term[complete.cases(gene_to_term),])
}
else
{
genesets = getGmt(con = gmtfile)
genesets = unlist(genesets)
gene_to_term <- data.frame(NA,NA)
names(gene_to_term) <- c("gene","term")
for (geneset in genesets)
{
temp <- geneIds(geneset)
temp2 <- setName(geneset)
temp3 <- as.data.frame(cbind(temp,rep(temp2,length(temp))))
names(temp3) <- c("gene","term")
gene_to_term <- rbind(gene_to_term,temp3)
}
return(gene_to_term[complete.cases(gene_to_term),])
}
}
#Main libraries
library(readr)
library(vsn)
#Support functions also requires
library(ggplot2)
library(reshape)
library(pheatmap)
library(gridExtra)
library(grid)
library(cowplot)
library(ggrepel)
library(hexbin)
library(org.Hs.eg.db)
library(AnnotationDbi)
library(decoupleR)
library(dorothea)
library(reshape2)
library(tidyr)
library(GSEABase)
library(fgsea)
library(progeny)
library(limma)
library(factoextra)
library(NbClust)
source("scripts/support/support_functions.R")
## Raw counts table
load(file = 'data/RNA/counts_result.RData')
gene_counts <- as.data.frame(counts_result$counts)
count_df <- gene_counts
names(count_df) <- gsub('.R1.fastq.gz.subread.BAM',"",names(count_df))
map_table <- AnnotationDbi::mapIds(org.Hs.eg.db::org.Hs.eg.db, row.names(count_df),'SYMBOL','ENTREZID')
count_df$gene <- sapply(row.names(count_df), function(x, map_table){
return(map_table[x])
},map_table = map_table)
count_df <- count_df[!is.na(count_df$gene),]
row.names(count_df) <- count_df$gene
count_df <- count_df[,-dim(count_df)[2]]
count_df <- count_df[complete.cases(count_df),]
write_csv(count_df, "../../data/RNA/counts_df.csv")
write_csv(count_df, "data/RNA/counts_df.csv")
read_per_samples <- colSums(count_df)
names(read_per_samples) <- names(count_df)
plot(read_per_samples)
mean(read_per_samples)
median(read_per_samples)
#First we remove rows that contain only 0
count_df <- count_df[rowSums(count_df) > 0,]
#remaining 0 have to be made as NA so that log2 transformation is possible
count_df[count_df == 0] <- NA
#make the plots
count_df_melt <- melt(log2(count_df))
ggplot(count_df_melt, aes(x = variable, y = value)) + geom_violin() +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
count_df[log2(count_df) < 5] <- NA
count_df_melt <- melt(log2(count_df))
ggplot(count_df_melt, aes(x = variable, y = value)) + geom_violin() +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
#remove rows (genes) which aren't well-measured in enough samples
count_df <- count_df[rowSums(is.na(count_df)) < 40,]
#now we can normalise the cleaned dataframe using vsn
fit <- vsnMatrix(as.matrix(count_df)) #train vsn parameters
#make sure the mean/sd trend is not going crazy
meanSdPlot(fit)
#if good, normalise data with the trained parameters of vsn
count_df_vsn <- as.data.frame(vsn::predict(fit,as.matrix(count_df)))
write_csv(count_df_vsn, "../../data/RNA/counts_df_normalised.csv")
write_csv(count_df_vsn, "data/RNA/counts_df_normalised.csv")
#now let's visualise the normalised data
targets <- as.data.frame(cbind(names(count_df_vsn),names(count_df_vsn)))
names(targets) <- c("sample","condition")
# plots <- magicPlotMakerLight(count_df_vsn, targets = targets)
# plot(plots[[1]])
# plot(plots[[2]])
dorothea_df <- dorothea_hs
dorothea_df <- dorothea_df[dorothea_df$confidence %in% c("A","B","C"),]
dorothea_df$likelihood <- 1
# TF_activity_mean <- run_mean(mat = as.matrix(count_df_vsn), network = dorothea_df, minsize = 15, times = 10000)
# save(TF_activity_mean, file = 'results/RNA/TF_activity_mean.RData')
load('results/RNA/TF_activity_mean.RData')
TF_activity_mean <- TF_activity_mean[TF_activity_mean$statistic == "normalized_mean",]
TF_activity_mean <- TF_activity_mean[,-c(1,5,6)]
names(TF_activity_mean)[3] <- "value"
TF_activity_mean_df <- dcast(TF_activity_mean, tf ~ condition, value.var = "value")
row.names(TF_activity_mean_df) <- TF_activity_mean_df$tf
TF_activity_mean_df <- TF_activity_mean_df[,-1]
TF_activity_meanrank_df <- as.data.frame(apply(TF_activity_mean_df, 2, base::rank))
View(TF_activity_mean_df)
View(TF_activity_meanrank_df)
write_csv(TF_activity_mean_df, "data/RNA/TF_df.csv")
# alternative clustering (these give small number of clusters, but we want to stratify more)
# Elbow method
df <- as.data.frame(t(TF_activity_meanrank_df))
fviz_nbclust(df, kmeans, method = "wss", k.max = 30) +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(df, kmeans, method = "silhouette", k.max = 30)+
labs(subtitle = "Silhouette method")
clusters<- kmeans(df, 5, iter.max = 10000, nstart = 100)
targets$condition <- paste0("C",clusters$cluster)
table(targets$condition)
getwd()
write_csv(targets,"supports/RNA_clusters_K5.csv")
row.names(targets) <- targets$sample
metadata_df <- targets[,2,drop = F]
targets <- targets[order(targets$condition),]
TF_activity_mean_df <- TF_activity_mean_df[,targets$sample]
pheatmap(TF_activity_mean_df, annotation_col = metadata_df, cluster_cols = F, width = 15, height = 30)
RNA_clusters_K5 <- as.data.frame(read_csv("supports/RNA_clusters_K5.csv"))
RNA_metadata <- as.data.frame(read_delim("supports/RNA_metadata.csv", ";", escape_double = FALSE, trim_ws = TRUE))
RNA_metadata <- merge(RNA_metadata, RNA_clusters_K5, by = 'sample')
RNA_metadata$ID <- gsub("HNE","Patient_",RNA_metadata$ID)
write(as.character(RNA_metadata$ID), file = "supports/patients_id_transcriptomic.txt")
TF_activity_cluster_avgrank <- sapply(unique(targets$condition), function(x, TF_activity_meanrank_df, targets){
df <- TF_activity_meanrank_df[,targets[targets$condition == x, 'sample']]
return(rowMeans(df))
}, TF_activity_meanrank_df = TF_activity_meanrank_df, targets = targets, USE.NAMES = T)
TF_activity_cluster_avgrank <- as.data.frame(TF_activity_cluster_avgrank)
SDs <- apply(TF_activity_cluster_avgrank, 1, sd)
SDs <- sort(SDs, decreasing = T)
SDs <- SDs[1:25]
TF_activity_cluster_avgrank_reduced <- TF_activity_cluster_avgrank[names(SDs),]
TF_activity_cluster_avgNES <- sapply(unique(targets$condition), function(x, TF_activity_mean_df, targets){
df <- TF_activity_mean_df[,targets[targets$condition == x, 'sample']]
return(rowMeans(df))
}, TF_activity_mean_df = TF_activity_mean_df, targets = targets, USE.NAMES = T)
TF_activity_cluster_avgNES <- as.data.frame(TF_activity_cluster_avgNES)
TF_activity_cluster_avgNES_reduced <- TF_activity_cluster_avgNES[names(SDs),]
# clustering <- pheatmap(TF_activity_cluster_avgrank_reduced, silent = F)
row_order <- names(SDs)
col_order <- names(sort(TF_activity_cluster_avgNES['STAT2',])) #sort columns by STAT2 gradient
TF_activity_cluster_avgrank_reduced <- TF_activity_cluster_avgrank_reduced[row_order, col_order]
TF_activity_cluster_avgNES_reduced <- TF_activity_cluster_avgNES_reduced[row_order, col_order]
pheatmap(TF_activity_cluster_avgrank_reduced, cluster_rows = F, cluster_cols = F)
pheatmap(TF_activity_cluster_avgNES_reduced, cluster_rows = F, cluster_cols = F)
View(TF_activity_cluster_avgrank)
View(TF_activity_cluster_avgNES)
write_csv(TF_activity_cluster_avgNES, "data/RNA/clusters_TF_df.csv")
cp_pathways <- import_gmt(gmtfile = 'supports/c2.cp.v7.2.symbols.gmt')
names(cp_pathways) <- c("target","tf")
cp_pathways$mor <- 1
cp_pathways$likelihood <- 1
cp_pathways <- cp_pathways[grepl("NABA_",cp_pathways$tf) |  grepl("KEGG_",cp_pathways$tf),]
# cp_pathway_mean <- run_mean(mat = as.matrix(count_df_vsn), network = cp_pathways, minsize = 15, times = 1000)
# save(cp_pathway_mean, file = 'results/RNA/cp_pathway_mean.RData')
load('results/RNA/cp_pathway_mean.RData')
cp_pathway_mean <- cp_pathway_mean[cp_pathway_mean$statistic == "normalized_mean",]
cp_pathway_mean <- cp_pathway_mean[,-c(1,5,6)]
names(cp_pathway_mean)[3] <- "value"
cp_pathway_mean_df <- dcast(cp_pathway_mean, tf ~ condition, value.var = "value")
row.names(cp_pathway_mean_df) <- cp_pathway_mean_df$tf
cp_pathway_mean_df <- cp_pathway_mean_df[,-1]
cp_pathway_meanrank_df <- as.data.frame(apply(cp_pathway_mean_df, 2, base::rank))
View(cp_pathway_meanrank_df)
View(cp_pathway_mean_df)
write_csv(cp_pathway_mean_df, "data/RNA/cp_pathways_df.csv")
colagen_df <- count_df_vsn[grepl("^COL[0-9]",row.names(count_df_vsn)) | row.names(count_df_vsn) == "FN1",]
colagen_df <- colagen_df[,targets$sample]
colagen_df_cluster_avgcount <- sapply(unique(targets$condition), function(x, colagen_df, targets){
df <- colagen_df[,targets[targets$condition == x, 'sample']]
return(rowMeans(df))
}, colagen_df = colagen_df, targets = targets, USE.NAMES = T)
colagen_df_cluster_sdcount <- sapply(unique(targets$condition), function(x, colagen_df, targets){
df <- colagen_df[,targets[targets$condition == x, 'sample']]
return(apply(df,1, sd, na.rm = TRUE))
}, colagen_df = colagen_df, targets = targets, USE.NAMES = T)
colagen_df_cluster_avgcount <- melt(colagen_df_cluster_avgcount)
colagen_df_cluster_sdcount <- melt(colagen_df_cluster_sdcount)
names(colagen_df_cluster_avgcount)[3] <- "mean_count"
colagen_df_cluster_avgcount$sd_count <- colagen_df_cluster_sdcount$value
p<- ggplot(colagen_df_cluster_avgcount, aes(x=Var1, y=mean_count, fill=Var2)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=mean_count-sd_count, ymax=mean_count+sd_count), width=.2,
position=position_dodge(.9))
p + theme_minimal() + theme(axis.text.x = element_text(face = "bold", color = "#993333",
size = 12, angle = 45))
View(count_df_vsn)
count_df_vsn["COL9A3"]
count_df_vsn["COL9A3",]
colagen_df <- count_df_vsn[grepl("^COL[0-9]",row.names(count_df_vsn)) | row.names(count_df_vsn) == "FN1",]
colagen_df <- colagen_df[,targets$sample]
colagen_df_cluster_avgcount <- sapply(unique(targets$condition), function(x, colagen_df, targets){
df <- colagen_df[,targets[targets$condition == x, 'sample']]
return(rowMeans(df, na.rm = T))
}, colagen_df = colagen_df, targets = targets, USE.NAMES = T)
colagen_df_cluster_sdcount <- sapply(unique(targets$condition), function(x, colagen_df, targets){
df <- colagen_df[,targets[targets$condition == x, 'sample']]
return(apply(df,1, sd, na.rm = TRUE))
}, colagen_df = colagen_df, targets = targets, USE.NAMES = T)
colagen_df_cluster_avgcount <- melt(colagen_df_cluster_avgcount)
colagen_df_cluster_sdcount <- melt(colagen_df_cluster_sdcount)
names(colagen_df_cluster_avgcount)[3] <- "mean_count"
colagen_df_cluster_avgcount$sd_count <- colagen_df_cluster_sdcount$value
p<- ggplot(colagen_df_cluster_avgcount, aes(x=Var1, y=mean_count, fill=Var2)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=mean_count-sd_count, ymax=mean_count+sd_count), width=.2,
position=position_dodge(.9))
p + theme_minimal() + theme(axis.text.x = element_text(face = "bold", color = "#993333",
size = 12, angle = 45))
dorothea_df <- dorothea_hs
dorothea_df <- dorothea_df[dorothea_df$confidence %in% c("A","B","C"),]
dorothea_df$likelihood <- 1
TF_activity_mean <- run_mean(mat = as.matrix(count_df_vsn), network = dorothea_df, minsize = 15, times = 10000)
# save(TF_activity_mean, file = 'results/RNA/TF_activity_mean.RData')
# load('results/RNA/TF_activity_mean.RData')
TF_activity_mean <- TF_activity_mean[TF_activity_mean$statistic == "normalized_mean",]
TF_activity_mean <- TF_activity_mean[,-c(1,5,6)]
names(TF_activity_mean)[3] <- "value"
TF_activity_mean_df <- dcast(TF_activity_mean, tf ~ condition, value.var = "value")
row.names(TF_activity_mean_df) <- TF_activity_mean_df$tf
TF_activity_mean_df <- TF_activity_mean_df[,-1]
TF_activity_meanrank_df <- as.data.frame(apply(TF_activity_mean_df, 2, base::rank))
# alternative clustering (these give small number of clusters, but we want to stratify more)
# Elbow method
df <- as.data.frame(t(TF_activity_meanrank_df))
fviz_nbclust(df, kmeans, method = "wss", k.max = 30) +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# alternative clustering (these give small number of clusters, but we want to stratify more)
# Elbow method
df <- as.data.frame(t(TF_activity_meanrank_df))
fviz_nbclust(df, kmeans, method = "wss", k.max = 30) +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
View(TF_activity_meanrank_df)
View(TF_activity_mean_df)
View(dorothea_df)
View(count_df_vsn)
View(TF_activity_mean)
run_mean()
run_mean
sum(dorothea_df$target %in% row.names(count_df_vsn))
TF_activity_mean <- run_mean(mat = as.matrix(count_df_vsn), network = dorothea_df, minsize = 15, times = 100, na.rm = T)
TF_activity_mean <- TF_activity_mean[TF_activity_mean$statistic == "normalized_mean",]
TF_activity_mean <- TF_activity_mean[,-c(1,5,6)]
names(TF_activity_mean)[3] <- "value"
TF_activity_mean_df <- dcast(TF_activity_mean, tf ~ condition, value.var = "value")
row.names(TF_activity_mean_df) <- TF_activity_mean_df$tf
TF_activity_mean_df <- TF_activity_mean_df[,-1]
View(TF_activity_cluster_avgrank)
View(TF_activity_mean_df)
TF_activity_mean <- run_mean(mat = as.matrix(count_df_vsn), network = dorothea_df, minsize = 15, times = 100, na.rm = T, sparse = F)
TF_activity_mean <- TF_activity_mean[TF_activity_mean$statistic == "normalized_mean",]
TF_activity_mean <- TF_activity_mean[,-c(1,5,6)]
names(TF_activity_mean)[3] <- "value"
TF_activity_mean_df <- dcast(TF_activity_mean, tf ~ condition, value.var = "value")
row.names(TF_activity_mean_df) <- TF_activity_mean_df$tf
TF_activity_mean_df <- TF_activity_mean_df[,-1]
View(TF_activity_mean_df)
TF_activity_mean <- run_mean(mat = as.matrix(count_df_vsn), network = dorothea_df, minsize = 15, times = 100, na.rm = T)
# save(TF_activity_mean, file = 'results/RNA/TF_activity_mean.RData')
# load('results/RNA/TF_activity_mean.RData')
TF_activity_mean <- TF_activity_mean[TF_activity_mean$statistic == "normalized_mean",]
TF_activity_mean <- TF_activity_mean[,-c(1,5,6)]
names(TF_activity_mean)[3] <- "value"
TF_activity_mean_df <- dcast(TF_activity_mean, tf ~ condition, value.var = "value")
row.names(TF_activity_mean_df) <- TF_activity_mean_df$tf
TF_activity_mean_df <- TF_activity_mean_df[,-1]
View(count_df_vsn)
library(viper)
View(dorothea_df)
dorothea_df <- dorothea_hs
dorothea_df <- dorothea_df[dorothea_df$confidence %in% c("A","B","C"),]
df_to_viper_regulon
View(dorothea_df)
df_to_viper_regulon(dorothea_df[,c(3,4,1)])
dorothea_viper <- df_to_viper_regulon(dorothea_df[,c(3,4,1)])
TF_activity_mean <- viper(eset = count_df_vsn, regulon = dorothea_viper, minsize = 15, eset.filter = F, pleiotropy = T, cores = 6)
TF_activity_mean <- viper(eset = count_df_vsn, regulon = dorothea_viper, minsize = 15, eset.filter = F, pleiotropy = T)
View(dorothea_viper)
dorothea_df[,c(3,4,1)]
dorothea_viper <- df_to_viper_regulon(as.data.frame(dorothea_df[,c(3,4,1)]))
View(dorothea_viper)
View(dorothea_viper)
as.data.frame(dorothea_df[,c(3,4,1)])
dorothea_viper <- df_to_viper_regulon(as.data.frame(dorothea_df[,c(3,1,4)]))
TF_activity_mean <- viper(eset = count_df_vsn, regulon = dorothea_viper, minsize = 15, eset.filter = F, pleiotropy = T)
TF_activity_meanrank_df <- as.data.frame(apply(TF_activity_mean_df, 2, base::rank))
TF_activity_mean_df <- as.data.frame(TF_activity_mean)
View(TF_activity_mean_df)
TF_activity_meanrank_df <- as.data.frame(apply(TF_activity_mean_df, 2, base::rank))
# alternative clustering (these give small number of clusters, but we want to stratify more)
# Elbow method
df <- as.data.frame(t(TF_activity_meanrank_df))
fviz_nbclust(df, kmeans, method = "wss", k.max = 30) +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(df, kmeans, method = "silhouette", k.max = 30)+
labs(subtitle = "Silhouette method")
clusters<- kmeans(df, 5, iter.max = 10000, nstart = 100)
targets$condition <- paste0("C",clusters$cluster)
table(targets$condition)
row.names(targets) <- targets$sample
metadata_df <- targets[,2,drop = F]
targets <- targets[order(targets$condition),]
TF_activity_mean_df <- TF_activity_mean_df[,targets$sample]
pheatmap(TF_activity_mean_df, annotation_col = metadata_df, cluster_cols = F, width = 15, height = 30)
TF_activity_cluster_avgrank <- sapply(unique(targets$condition), function(x, TF_activity_meanrank_df, targets){
df <- TF_activity_meanrank_df[,targets[targets$condition == x, 'sample']]
return(rowMeans(df))
}, TF_activity_meanrank_df = TF_activity_meanrank_df, targets = targets, USE.NAMES = T)
TF_activity_cluster_avgrank <- as.data.frame(TF_activity_cluster_avgrank)
SDs <- apply(TF_activity_cluster_avgrank, 1, sd)
SDs <- sort(SDs, decreasing = T)
SDs <- SDs[1:25]
TF_activity_cluster_avgrank_reduced <- TF_activity_cluster_avgrank[names(SDs),]
TF_activity_cluster_avgNES <- sapply(unique(targets$condition), function(x, TF_activity_mean_df, targets){
df <- TF_activity_mean_df[,targets[targets$condition == x, 'sample']]
return(rowMeans(df))
}, TF_activity_mean_df = TF_activity_mean_df, targets = targets, USE.NAMES = T)
TF_activity_cluster_avgNES <- as.data.frame(TF_activity_cluster_avgNES)
TF_activity_cluster_avgNES_reduced <- TF_activity_cluster_avgNES[names(SDs),]
row_order <- names(SDs)
col_order <- names(sort(TF_activity_cluster_avgNES['STAT2',])) #sort columns by STAT2 gradient
TF_activity_cluster_avgrank_reduced <- TF_activity_cluster_avgrank_reduced[row_order, col_order]
TF_activity_cluster_avgNES_reduced <- TF_activity_cluster_avgNES_reduced[row_order, col_order]
pheatmap(TF_activity_cluster_avgrank_reduced, cluster_rows = F, cluster_cols = F)
pheatmap(TF_activity_cluster_avgNES_reduced, cluster_rows = F, cluster_cols = F)
library(readr)
phospho_differential_analysis <- read_csv("Dropbox/kinase_tf_mini_tuto/data/phospho_differential_analysis.csv")
View(phospho_differential_analysis)
row.names(phospho_differential_analysis) <- phospho_differential_analysis$psite_ID
setwd("Dropbox/kinase_tf_mini_tuto/")
phospho_differential_analysis <- as.data.frame(
read_csv("data/phospho_differential_analysis.csv"))
row.names(phospho_differential_analysis) <- phospho_differential_analysis$psite_ID
phospho_differential_analysis <- phospho_differential_analysis[,-1]
library(readr)
setwd("Dropbox/kinase_tf_mini_tuto/")
phospho_differential_analysis <- as.data.frame(
read_csv("data/phospho_differential_analysis.csv"))
row.names(phospho_differential_analysis) <- phospho_differential_analysis$psite_ID
phospho_differential_analysis <- phospho_differential_analysis[,-1, drop = F]
View(phospho_differential_analysis)
library(OmnipathR)
library(viper)
omnipath_ptm <- get_ptms_databases()
omnipath_ptm <- get_signed_ptms()
View(omnipath_ptm)
omnipath_ptm <- omnipath_ptm[omnipath_ptm$modification %in% c("dephosphorylation","phosphorylation"),]
View(omnipath_ptm)
KSN <- omnipath_ptm[,c(4,3)]
KSN$substrate_genesymbol <- paste(KSN$substrate_genesymbol,omnipath_ptm$residue_type, sep ="_")
KSN$substrate_genesymbol <- paste(KSN$substrate_genesymbol,omnipath_ptm$residue_offset, sep = "")
KSN$sign <- ifelse(omnipath_ptm$modification == "phosphorylation", 1, -1)
View(KSN)
source("scripts/viper_functions.R")
setwd("Dropbox/kinase_tf_mini_tuto/")
source("scripts/viper_functions.R")
setwd(~/"Dropbox/kinase_tf_mini_tuto/")
setwd("~/Dropbox/kinase_tf_mini_tuto/")
source("scripts/viper_functions.R")
source("script/viper_functions.R")
library(readr)
library(viper)
setwd("~/Dropbox/kinase_tf_mini_tuto/")
source("script/viper_functions.R")
########## PHOSHO and KINASE part ########
library(OmnipathR)
phospho_differential_analysis <- as.data.frame(
read_csv("data/phospho_differential_analysis.csv"))
row.names(phospho_differential_analysis) <- phospho_differential_analysis$psite_ID
phospho_differential_analysis <- phospho_differential_analysis[,-1, drop = F]
#inport KSN from omnipath and format it
omnipath_ptm <- get_signed_ptms()
omnipath_ptm <- omnipath_ptm[omnipath_ptm$modification %in% c("dephosphorylation","phosphorylation"),]
KSN <- omnipath_ptm[,c(4,3)]
KSN$substrate_genesymbol <- paste(KSN$substrate_genesymbol,omnipath_ptm$residue_type, sep ="_")
KSN$substrate_genesymbol <- paste(KSN$substrate_genesymbol,omnipath_ptm$residue_offset, sep = "")
KSN$sign <- ifelse(omnipath_ptm$modification == "phosphorylation", 1, -1)
KSN_viper <- df_to_viper_regulon(KSN)
kin_activity <- as.data.frame(viper(eset = viper_expression, regulon = KSN_viper, minsize = 5, adaptive.size = F, eset.filter = F))
kin_activity <- as.data.frame(viper(eset = phospho_differential_analysis, regulon = KSN_viper, minsize = 5, adaptive.size = F, eset.filter = F))
View(kin_activity)
library(dorothea)
View(phospho_differential_analysis)
dorothea_df<- as.data.frame(dorothea_hs[dorothea_hs$confidence %in% c("A","B","C"),c(3,1,4)])
RNA_differential_analysis <- as.data.frame(
read_csv("data/RNA_differential_analysis.csv"))
View(RNA_differential_analysis)
RNAseq_entrez_to_symbol <- as.data.frame(read_delim("support/RNAseq_entrez_to_symbol",
"\t", escape_double = FALSE, col_types = cols(`yourlist:M20191127216DA2B77BFBD2E6699CA9B6D1C41EB259129CL` = col_character()),
trim_ws = TRUE)) #from uniprot 20191127
names(RNAseq_entrez_to_symbol)[1] <- "ID"
RNA_differential_analysis <- merge(RNA_differential_analysis, RNAseq_entrez_to_symbol[,c(1,6)])
RNA_differential_analysis <- RNA_differential_analysis[,c(8,2:7)]
names(RNA_differential_analysis)[1] <- "ID"
RNA_differential_analysis$ID <- gsub(" .*","",RNA_differential_analysis$ID)
RNA_differential_analysis <- unique(RNA_differential_analysis)
eset <- RNA_differential_analysis$t
names(eset) <- RNA_differential_analysis$ID
#we also need to format the dorothea dataframe into a viper format
dorothea_viper <- df_to_viper_regulon(dorothea_df)
viperRes <- as.data.frame(viper(eset = eset, regulon = dorothea_viper, minsize = 10, adaptive.size = F, eset.filter = F, pleiotropy = T))
viperRes$TF <- row.names(viperRes)
viperRes <- viperRes[,c(2,1)]
names(viperRes) <- c("ID","NES")
View(viperRes)
#Now we estimate the TF activities using viper
TF_activities <- as.data.frame(viper(eset = eset, regulon = dorothea_viper, minsize = 10, adaptive.size = F, eset.filter = F, pleiotropy = T))
TF_activities$TF <- row.names(TF_activities)
#that's just to make the dataframe pretty
TF_activities <- TF_activities[,c(2,1)]
names(TF_activities) <- c("ID","NES")
library(workflowr)
install.packages('workflowr')
library(workflowr)
wflow_build('analysis/*.Rmd')
install.packages('here')
wflow_build('analysis/*.Rmd')
BiocManager::install(c('viper','OmnipathR','org.Hs.eg.db', 'dorothea'))
BiocManager::install(c('viper','OmnipathR','org.Hs.eg.db', 'dorothea'))
BiocManager::install()
wflow_build('analysis/*Rmd')
BiocManager::install('viper')
BiocManager::install('viper', force = TRUE)
wflow_build('analysis/*.Rmd')
